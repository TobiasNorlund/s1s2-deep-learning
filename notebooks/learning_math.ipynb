{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '+',\n",
       " '=',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'F',\n",
       " '!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCABULARY = [str(d) for d in range(10)] + ['+', '=', 'Q', 'E', 'F', '!']\n",
    "VOCABULARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97+53Q0+7+3E10Q1+9+5E15F150!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data(n_samples, max_n_digits, seed, min_n_digits=1):\n",
    "    random.seed(seed)\n",
    "    already_generated = set()\n",
    "    \n",
    "    while True:\n",
    "        if len(already_generated) >= n_samples:\n",
    "            break\n",
    "        \n",
    "        n_digits = random.randint(min_n_digits, max_n_digits)\n",
    "        \n",
    "        a = random.randint(0, 10 ** n_digits - 1)\n",
    "        b = random.randint(0, 10 ** n_digits - 1)\n",
    "        \n",
    "        if (a, b) in already_generated:\n",
    "            continue\n",
    "        \n",
    "        already_generated.add((a, b))\n",
    "        \n",
    "        problem = f'{a:0{n_digits}d}+{b:0{n_digits}d}'\n",
    "\n",
    "        carry = 0\n",
    "        \n",
    "        for significance in range(n_digits):\n",
    "            a_digit = (a // 10 ** significance) % 10\n",
    "            b_digit = (b // 10 ** significance) % 10\n",
    "            result = a_digit + b_digit + carry\n",
    "            result_digit = result % 10\n",
    "            result_carry = result // 10\n",
    "            problem += f'Q{carry}+{a_digit}+{b_digit}E{result_carry}{result_digit}'\n",
    "            carry = result_carry\n",
    "        \n",
    "        problem += f'F{a+b}!'\n",
    "        \n",
    "        yield problem\n",
    "\n",
    "next(data(100, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    s = list(s)\n",
    "    return np.array([VOCABULARY.index(c) for c in s])\n",
    "\n",
    "def detokenize(arr):\n",
    "    return ''.join([VOCABULARY[x] for x in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def system_1(s):\n",
    "    return f'{eval(s):02d}'\n",
    "\n",
    "system_1('7+1+0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset):\n",
    "    for example in dataset:\n",
    "        idxs = [(m.start(0), m.end(0))\n",
    "                for m in re.finditer('Q.\\+.\\+.E|F.*!', example[1:])]\n",
    "        \n",
    "        tokens = tokenize(example)\n",
    "        inputs = tokens[:-1]\n",
    "        targets = tokens[1:]\n",
    "        \n",
    "        mask = np.array([0] * len(targets))\n",
    "        for s, e in idxs:\n",
    "            mask[s:e] = 1\n",
    "        \n",
    "        yield inputs, targets, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(model, a, b):\n",
    "    n_digits = max(len(str(a)), len(str(b)))\n",
    "    ex = f\"{a:0{n_digits}d}+{b:0{n_digits}d}\"\n",
    "    tokenized = tokenize(ex)\n",
    "    \n",
    "    while True:\n",
    "        while not tokenized[-1] in (VOCABULARY.index('E'), VOCABULARY.index('!')):\n",
    "            pred = model(tokenized[np.newaxis, ...]).numpy()\n",
    "            next_token = np.argmax(pred, axis=-1)[0, -1]\n",
    "            tokenized = np.append(tokenized, next_token)\n",
    "\n",
    "        if tokenized[-1] == VOCABULARY.index('E'):\n",
    "            # Call system 1\n",
    "            query = detokenize(tokenized)[-6:-1]\n",
    "            ans = system_1(query)\n",
    "            tokenized_ans = tokenize(ans)\n",
    "            tokenized = np.append(tokenized, tokenized_ans)\n",
    "\n",
    "        elif tokenized[-1] == VOCABULARY.index('!'):\n",
    "            break\n",
    "\n",
    "    return detokenize(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset):\n",
    "    n_correct = 0\n",
    "    for example in test_dataset:\n",
    "        i = example.index('Q')\n",
    "        ab = example[:i]\n",
    "        i = ab.index('+')\n",
    "        a = int(ab[:i])\n",
    "        b = int(ab[i:])\n",
    "\n",
    "        try:\n",
    "            ans = decode(model, a, b)\n",
    "            i = ans.index('F')\n",
    "            ans = ans[i+1:-1]\n",
    "            ans = int(ans)\n",
    "\n",
    "            if ans == a + b:\n",
    "                n_correct += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return n_correct / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, use_attention):\n",
    "    inputs = layers.Input((None,))\n",
    "    x = inputs\n",
    "    x = layers.Embedding(vocab_size, 64)(x)\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    \n",
    "    if use_attention:\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        keys = layers.Dense(128)(x)\n",
    "        look_ahead_mask = (1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)) * -1e9\n",
    "        look_ahead_mask = look_ahead_mask[tf.newaxis, ...]\n",
    "        attention_scores = x @ tf.transpose(keys, [0, 2, 1])\n",
    "        attention_scores = attention_scores + look_ahead_mask\n",
    "        attention_weights = tf.nn.softmax(attention_scores, name=\"attention_weights\")\n",
    "        x_att = attention_weights @ x\n",
    "        x = layers.Concatenate()([x, x_att])\n",
    "    \n",
    "    x = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    model = models.Model(inputs, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_experiment(train_dataset, test_dataset, use_attention):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    vocab_size = len(VOCABULARY)\n",
    "    model = build_model(vocab_size, use_attention)\n",
    "\n",
    "    optimizer = optimizers.Adam(1e-3)\n",
    "\n",
    "    model.build(input_shape=(None, None))\n",
    "    model.summary()\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(\n",
    "        lambda: data_generator(train_dataset),\n",
    "        output_types=(tf.int32, tf.int32, tf.int32),\n",
    "        output_shapes=(\n",
    "            tf.TensorShape((None,)), \n",
    "            tf.TensorShape((None,)), \n",
    "            tf.TensorShape((None,))\n",
    "        ))\n",
    "    train_ds = train_ds.shuffle(10000)\n",
    "    train_ds = train_ds.padded_batch(16, padded_shapes=([None], [None], [None]))\n",
    "\n",
    "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(inputs, targets, mask):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(inputs)\n",
    "            loss = tf.losses.sparse_categorical_crossentropy(targets, outputs)\n",
    "            loss = tf.boolean_mask(loss, tf.cast(mask, tf.bool))\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            masked_outputs = tf.boolean_mask(outputs, tf.cast(mask, tf.bool))\n",
    "            accuracy(targets, outputs, sample_weight=mask)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    for i, (inputs, targets, mask) in train_ds.repeat(None).take(4000).enumerate():\n",
    "        accuracy.reset_states()\n",
    "        loss = train_step(inputs, targets, mask)\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(\n",
    "                'Step', i.numpy(),\n",
    "                'Loss', loss.numpy(),\n",
    "                'Acc', accuracy.result().numpy())\n",
    "    \n",
    "    accuracy = evaluate(model, test_dataset)\n",
    "    return accuracy, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 64)          1024      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 16)          2064      \n",
      "=================================================================\n",
      "Total params: 101,904\n",
      "Trainable params: 101,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/StatefulPartitionedCall]] [Op:__inference_train_step_3051]\n\nFunction call stack:\ntrain_step -> train_step -> train_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a50e466734f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_train_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b45b1f2a751d>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(train_dataset, test_dataset, use_attention)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             print(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/StatefulPartitionedCall]] [Op:__inference_train_step_3051]\n\nFunction call stack:\ntrain_step -> train_step -> train_step\n"
     ]
    }
   ],
   "source": [
    "dataset = data(\n",
    "    n_samples=5000,\n",
    "    max_n_digits=2,\n",
    "    seed=0)\n",
    "dataset = list(dataset)\n",
    "\n",
    "test_dataset = dataset[-300:]\n",
    "\n",
    "n_train_sizes = [100, 500, 1000, 2000]\n",
    "accuracies = []\n",
    "for n_train in n_train_sizes:\n",
    "    train_dataset = dataset[:n_train]\n",
    "    accuracy, _ = run_experiment(train_dataset, test_dataset, use_attention=False)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(n_train_sizes, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline + self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 128)    98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_packed (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones (TensorFlowOpL [(None, None)]       0           tf_op_layer_packed[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatrixBandPart (Ten [(None, None)]       0           tf_op_layer_ones[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    16512       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, None)]       0           tf_op_layer_MatrixBandPart[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 128, None)]  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul (TensorFlowO [(None, None, None)] 0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(1, None, None)]    0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, None, None)] 0           tf_op_layer_matmul[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, None, None)] 0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul_1 (TensorFlo [(None, None, 128)]  0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 256)    0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_matmul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 16)     4112        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 120,464\n",
      "Trainable params: 120,464\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Step 100 Loss 1.5265988 Acc 0.6523605\n",
      "Step 200 Loss 0.7810193 Acc 0.7314815\n",
      "Step 300 Loss 0.7387581 Acc 0.75757575\n",
      "Step 400 Loss 0.6189726 Acc 0.79385966\n",
      "Step 500 Loss 0.54199016 Acc 0.81893003\n",
      "Step 600 Loss 0.38730654 Acc 0.8888889\n",
      "Step 700 Loss 0.31171846 Acc 0.8959276\n",
      "Step 800 Loss 0.2492314 Acc 0.92444444\n",
      "Step 900 Loss 0.16611883 Acc 0.969697\n",
      "Step 1000 Loss 0.105924465 Acc 1.0\n",
      "Step 1100 Loss 0.07281127 Acc 0.99122804\n",
      "Step 1200 Loss 0.04543132 Acc 1.0\n",
      "Step 1300 Loss 0.035700586 Acc 1.0\n",
      "Step 1400 Loss 0.02248847 Acc 1.0\n",
      "Step 1500 Loss 0.018834947 Acc 1.0\n",
      "Step 1600 Loss 0.20105673 Acc 0.9596774\n",
      "Step 1700 Loss 0.025917744 Acc 1.0\n",
      "Step 1800 Loss 0.015610667 Acc 1.0\n",
      "Step 1900 Loss 0.0100904815 Acc 1.0\n",
      "Step 2000 Loss 0.0076411744 Acc 1.0\n",
      "Step 2100 Loss 0.008156694 Acc 1.0\n",
      "Step 2200 Loss 0.0062507447 Acc 1.0\n",
      "Step 2300 Loss 0.00520887 Acc 1.0\n",
      "Step 2400 Loss 0.004598132 Acc 1.0\n",
      "Step 2500 Loss 0.004217026 Acc 1.0\n",
      "Step 2600 Loss 0.0035851153 Acc 1.0\n",
      "Step 2700 Loss 0.00293638 Acc 1.0\n",
      "Step 2800 Loss 0.0026258798 Acc 1.0\n",
      "Step 2900 Loss 0.0028528941 Acc 1.0\n",
      "Step 3000 Loss 0.002325041 Acc 1.0\n",
      "Step 3100 Loss 0.002472267 Acc 1.0\n",
      "Step 3200 Loss 0.001730805 Acc 1.0\n",
      "Step 3300 Loss 0.0017172941 Acc 1.0\n",
      "Step 3400 Loss 0.0013168223 Acc 1.0\n",
      "Step 3500 Loss 0.0012495329 Acc 1.0\n",
      "Step 3600 Loss 0.0015239044 Acc 1.0\n",
      "Step 3700 Loss 0.0012122514 Acc 1.0\n",
      "Step 3800 Loss 0.0010840888 Acc 1.0\n",
      "Step 3900 Loss 0.001189165 Acc 1.0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 128)    98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_packed (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones (TensorFlowOpL [(None, None)]       0           tf_op_layer_packed[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatrixBandPart (Ten [(None, None)]       0           tf_op_layer_ones[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    16512       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, None)]       0           tf_op_layer_MatrixBandPart[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 128, None)]  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul (TensorFlowO [(None, None, None)] 0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(1, None, None)]    0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, None, None)] 0           tf_op_layer_matmul[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, None, None)] 0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul_1 (TensorFlo [(None, None, 128)]  0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 256)    0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_matmul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 16)     4112        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 120,464\n",
      "Trainable params: 120,464\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 1.9898735 Acc 0.32971016\n",
      "Step 200 Loss 0.99012864 Acc 0.66793895\n",
      "Step 300 Loss 0.8520586 Acc 0.69473684\n",
      "Step 400 Loss 0.74131805 Acc 0.74169743\n",
      "Step 500 Loss 0.7321281 Acc 0.7394636\n",
      "Step 600 Loss 0.699945 Acc 0.7490494\n",
      "Step 700 Loss 0.67464167 Acc 0.7557252\n",
      "Step 800 Loss 0.6465579 Acc 0.76981133\n",
      "Step 900 Loss 0.6057996 Acc 0.8015267\n",
      "Step 1000 Loss 0.5836463 Acc 0.810219\n",
      "Step 1100 Loss 0.42980906 Acc 0.87649405\n",
      "Step 1200 Loss 0.41732126 Acc 0.8774704\n",
      "Step 1300 Loss 0.31744236 Acc 0.91007197\n",
      "Step 1400 Loss 0.3068247 Acc 0.905303\n",
      "Step 1500 Loss 0.21554098 Acc 0.9421769\n",
      "Step 1600 Loss 0.22441018 Acc 0.93050194\n",
      "Step 1700 Loss 0.18656848 Acc 0.95272726\n",
      "Step 1800 Loss 0.13914895 Acc 0.9651568\n",
      "Step 1900 Loss 0.14914002 Acc 0.9520295\n",
      "Step 2000 Loss 0.081030026 Acc 0.98916966\n",
      "Step 2100 Loss 0.07244222 Acc 0.98046875\n",
      "Step 2200 Loss 0.07107093 Acc 0.984375\n",
      "Step 2300 Loss 0.049197726 Acc 0.9965278\n",
      "Step 2400 Loss 0.03661329 Acc 0.9961832\n",
      "Step 2500 Loss 0.03013873 Acc 0.9962825\n",
      "Step 2600 Loss 0.023275198 Acc 1.0\n",
      "Step 2700 Loss 0.018788477 Acc 1.0\n",
      "Step 2800 Loss 0.016840067 Acc 1.0\n",
      "Step 2900 Loss 0.0128802955 Acc 1.0\n",
      "Step 3000 Loss 0.009825512 Acc 1.0\n",
      "Step 3100 Loss 0.010053929 Acc 1.0\n",
      "Step 3200 Loss 0.008500588 Acc 1.0\n",
      "Step 3300 Loss 0.007683661 Acc 1.0\n",
      "Step 3400 Loss 0.00628719 Acc 1.0\n",
      "Step 3500 Loss 0.0051383027 Acc 1.0\n",
      "Step 3600 Loss 0.005105108 Acc 1.0\n",
      "Step 3700 Loss 0.0042773746 Acc 1.0\n",
      "Step 3800 Loss 0.0032168066 Acc 1.0\n",
      "Step 3900 Loss 0.0034416076 Acc 1.0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 128)    98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_packed (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones (TensorFlowOpL [(None, None)]       0           tf_op_layer_packed[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatrixBandPart (Ten [(None, None)]       0           tf_op_layer_ones[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    16512       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, None)]       0           tf_op_layer_MatrixBandPart[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 128, None)]  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul (TensorFlowO [(None, None, None)] 0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(1, None, None)]    0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, None, None)] 0           tf_op_layer_matmul[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, None, None)] 0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul_1 (TensorFlo [(None, None, 128)]  0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 256)    0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_matmul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 16)     4112        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 120,464\n",
      "Trainable params: 120,464\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Step 100 Loss 1.8147304 Acc 0.5017544\n",
      "Step 200 Loss 0.9649557 Acc 0.6812081\n",
      "Step 300 Loss 0.906262 Acc 0.6703297\n",
      "Step 400 Loss 0.7873634 Acc 0.72727275\n",
      "Step 500 Loss 0.7207861 Acc 0.76978415\n",
      "Step 600 Loss 0.67692465 Acc 0.76870745\n",
      "Step 700 Loss 0.62254983 Acc 0.7979094\n",
      "Step 800 Loss 0.5336558 Acc 0.8645833\n",
      "Step 900 Loss 0.38725346 Acc 0.90625\n",
      "Step 1000 Loss 0.1784739 Acc 0.9657795\n",
      "Step 1100 Loss 0.11142507 Acc 0.98207885\n",
      "Step 1200 Loss 0.051261242 Acc 0.99655175\n",
      "Step 1300 Loss 0.04050534 Acc 0.99622643\n",
      "Step 1400 Loss 0.01612546 Acc 1.0\n",
      "Step 1500 Loss 0.027386205 Acc 0.9930556\n",
      "Step 1600 Loss 0.009921725 Acc 1.0\n",
      "Step 1700 Loss 0.005432231 Acc 1.0\n",
      "Step 1800 Loss 0.005908797 Acc 1.0\n",
      "Step 1900 Loss 0.004931031 Acc 1.0\n",
      "Step 2000 Loss 0.0038713515 Acc 1.0\n",
      "Step 2100 Loss 0.0038878787 Acc 1.0\n",
      "Step 2200 Loss 0.0032278025 Acc 1.0\n",
      "Step 2300 Loss 0.0023624275 Acc 1.0\n",
      "Step 2400 Loss 0.002506253 Acc 1.0\n",
      "Step 2500 Loss 0.0021180324 Acc 1.0\n",
      "Step 2600 Loss 0.0018331147 Acc 1.0\n",
      "Step 2700 Loss 0.0017850574 Acc 1.0\n",
      "Step 2800 Loss 0.0013598121 Acc 1.0\n",
      "Step 2900 Loss 0.0011384123 Acc 1.0\n",
      "Step 3000 Loss 0.0012378746 Acc 1.0\n",
      "Step 3100 Loss 0.0013356719 Acc 1.0\n",
      "Step 3200 Loss 0.0012452321 Acc 1.0\n",
      "Step 3300 Loss 0.0008897392 Acc 1.0\n",
      "Step 3400 Loss 0.0008619233 Acc 1.0\n",
      "Step 3500 Loss 0.0008087305 Acc 1.0\n",
      "Step 3600 Loss 0.0007086073 Acc 1.0\n",
      "Step 3700 Loss 0.0006585504 Acc 1.0\n",
      "Step 3800 Loss 0.00061722903 Acc 1.0\n",
      "Step 3900 Loss 0.00054514746 Acc 1.0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 128)    98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_packed (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones (TensorFlowOpL [(None, None)]       0           tf_op_layer_packed[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatrixBandPart (Ten [(None, None)]       0           tf_op_layer_ones[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    16512       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, None)]       0           tf_op_layer_MatrixBandPart[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 128, None)]  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul (TensorFlowO [(None, None, None)] 0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(1, None, None)]    0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, None, None)] 0           tf_op_layer_matmul[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, None, None)] 0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul_1 (TensorFlo [(None, None, 128)]  0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 256)    0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_matmul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 16)     4112        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 120,464\n",
      "Trainable params: 120,464\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 1.8116287 Acc 0.42857143\n",
      "Step 200 Loss 0.9507092 Acc 0.6840278\n",
      "Step 300 Loss 0.80750275 Acc 0.7003367\n",
      "Step 400 Loss 0.7629979 Acc 0.7133106\n",
      "Step 500 Loss 0.70806277 Acc 0.762069\n",
      "Step 600 Loss 0.6878488 Acc 0.75165564\n",
      "Step 700 Loss 0.6604581 Acc 0.779661\n",
      "Step 800 Loss 0.5838169 Acc 0.8263889\n",
      "Step 900 Loss 0.5539381 Acc 0.8361204\n",
      "Step 1000 Loss 0.4969657 Acc 0.8333333\n",
      "Step 1100 Loss 0.44052565 Acc 0.85423726\n",
      "Step 1200 Loss 0.37060526 Acc 0.8783784\n",
      "Step 1300 Loss 0.30904925 Acc 0.8993289\n",
      "Step 1400 Loss 0.2528461 Acc 0.9151291\n",
      "Step 1500 Loss 0.19364119 Acc 0.9522059\n",
      "Step 1600 Loss 0.17364648 Acc 0.9547038\n",
      "Step 1700 Loss 0.13346103 Acc 0.9652778\n",
      "Step 1800 Loss 0.07725545 Acc 0.9896194\n",
      "Step 1900 Loss 0.04315991 Acc 0.9932432\n",
      "Step 2000 Loss 0.037057817 Acc 1.0\n",
      "Step 2100 Loss 0.030888809 Acc 0.9932432\n",
      "Step 2200 Loss 0.03366283 Acc 1.0\n",
      "Step 2300 Loss 0.023877416 Acc 0.9965157\n",
      "Step 2400 Loss 0.010960712 Acc 1.0\n",
      "Step 2500 Loss 0.0072420896 Acc 1.0\n",
      "Step 2600 Loss 0.009338946 Acc 1.0\n",
      "Step 2700 Loss 0.0072406023 Acc 1.0\n",
      "Step 2800 Loss 0.0048747 Acc 1.0\n",
      "Step 2900 Loss 0.0042687817 Acc 1.0\n",
      "Step 3000 Loss 0.0036011836 Acc 1.0\n",
      "Step 3100 Loss 0.0038311991 Acc 1.0\n",
      "Step 3200 Loss 0.0023287917 Acc 1.0\n",
      "Step 3300 Loss 0.0025006898 Acc 1.0\n",
      "Step 3400 Loss 0.0025733965 Acc 1.0\n",
      "Step 3500 Loss 0.007290499 Acc 1.0\n",
      "Step 3600 Loss 0.0059079574 Acc 1.0\n",
      "Step 3700 Loss 0.007986957 Acc 1.0\n",
      "Step 3800 Loss 0.002054022 Acc 1.0\n",
      "Step 3900 Loss 0.0014158277 Acc 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data(\n",
    "    n_samples=5000,\n",
    "    max_n_digits=2,\n",
    "    seed=0)\n",
    "dataset = list(dataset)\n",
    "\n",
    "test_dataset = dataset[-300:]\n",
    "\n",
    "n_train_sizes = [100, 500, 1000, 2000]\n",
    "accuracies = []\n",
    "for n_train in n_train_sizes:\n",
    "    train_dataset = dataset[:n_train]\n",
    "    accuracy, _ = run_experiment(train_dataset, test_dataset, use_attention=True)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(n_train_sizes, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05, 0.9433333333333334, 1.0, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing num digits in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 128)    98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(3,)]               0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_packed (TensorFlowO [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ones (TensorFlowOpL [(None, None)]       0           tf_op_layer_packed[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatrixBandPart (Ten [(None, None)]       0           tf_op_layer_ones[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    16512       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, None)]       0           tf_op_layer_MatrixBandPart[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose (TensorFl [(None, 128, None)]  0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_1 (TensorFlowOp [(None, None)]       0           tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul (TensorFlowO [(None, None, None)] 0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_transpose[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(1, None, None)]    0           tf_op_layer_mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, None, None)] 0           tf_op_layer_matmul[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorFlow [(None, None, None)] 0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_matmul_1 (TensorFlo [(None, None, 128)]  0           tf_op_layer_Softmax[0][0]        \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 256)    0           lstm[0][0]                       \n",
      "                                                                 tf_op_layer_matmul_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 16)     4112        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 120,464\n",
      "Trainable params: 120,464\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Step 100 Loss 1.4674286 Acc 0.57416266\n",
      "Step 200 Loss 0.8816992 Acc 0.6775\n",
      "Step 300 Loss 0.798746 Acc 0.7076566\n",
      "Step 400 Loss 0.83192813 Acc 0.686747\n",
      "Step 500 Loss 0.7658208 Acc 0.7067308\n",
      "Step 600 Loss 0.7644285 Acc 0.7193396\n",
      "Step 700 Loss 0.7417636 Acc 0.7477273\n",
      "Step 800 Loss 0.6975254 Acc 0.7582697\n",
      "Step 900 Loss 0.72670346 Acc 0.7518797\n",
      "Step 1000 Loss 0.67451984 Acc 0.7718447\n",
      "Step 1100 Loss 0.682075 Acc 0.76658475\n",
      "Step 1200 Loss 0.6591097 Acc 0.7829615\n",
      "Step 1300 Loss 0.48236194 Acc 0.85491073\n",
      "Step 1400 Loss 0.25679475 Acc 0.9395973\n",
      "Step 1500 Loss 0.15730982 Acc 0.9489559\n",
      "Step 1600 Loss 0.11589498 Acc 0.96875\n",
      "Step 1700 Loss 0.10961876 Acc 0.96145123\n",
      "Step 1800 Loss 0.07730319 Acc 0.98288506\n",
      "Step 1900 Loss 0.04344292 Acc 0.9951807\n",
      "Step 2000 Loss 0.051065803 Acc 0.99022007\n",
      "Step 2100 Loss 0.04793549 Acc 0.98398167\n",
      "Step 2200 Loss 0.083230674 Acc 0.97167754\n",
      "Step 2300 Loss 0.040255982 Acc 0.9949367\n",
      "Step 2400 Loss 0.034650914 Acc 0.98740554\n",
      "Step 2500 Loss 0.034549076 Acc 0.9880383\n",
      "Step 2600 Loss 0.027489142 Acc 0.9951691\n",
      "Step 2700 Loss 0.0255086 Acc 0.9923274\n",
      "Step 2800 Loss 0.036810327 Acc 0.99117\n",
      "Step 2900 Loss 0.027827123 Acc 0.9952941\n",
      "Step 3000 Loss 0.014309227 Acc 0.9946808\n",
      "Step 3100 Loss 0.017691756 Acc 0.9977324\n",
      "Step 3200 Loss 0.019406682 Acc 0.99234694\n",
      "Step 3300 Loss 0.01955707 Acc 0.9976526\n",
      "Step 3400 Loss 0.010221144 Acc 0.997389\n",
      "Step 3500 Loss 0.01842557 Acc 0.9955556\n",
      "Step 3600 Loss 0.029722137 Acc 0.9921875\n",
      "Step 3700 Loss 0.014165236 Acc 0.99264705\n",
      "Step 3800 Loss 0.009602305 Acc 1.0\n",
      "Step 3900 Loss 0.0098105585 Acc 1.0\n",
      "0.008\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data(\n",
    "    n_samples=5000,\n",
    "    max_n_digits=4,\n",
    "    seed=0)\n",
    "train_dataset = list(train_dataset)\n",
    "\n",
    "test_dataset = data(\n",
    "    n_samples=500,\n",
    "    max_n_digits=5,\n",
    "    min_n_digits=5,\n",
    "    seed=0)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "accuracy, model = run_experiment(train_dataset, test_dataset, use_attention=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detokenize(decode(model, 11111, 22222)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax output:\n",
      "tf.Tensor(\n",
      "[2.8037343e-11 5.2746945e-09 1.8141233e-10 1.4013974e-09 7.9117997e-11\n",
      " 3.3210892e-10 1.3350846e-09 5.2551175e-11 8.3795415e-11 2.2186410e-09\n",
      " 5.5160859e-10 2.0774592e-11 9.9997485e-01 1.9936708e-05 5.1865363e-06\n",
      " 5.8551095e-11], shape=(16,), dtype=float32)\n",
      "Argmax token: Q\n",
      "Attention weights:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd5ff180a20>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex = \"123+567Q0+3+7E1\"\n",
    "tokenized = tokenize(ex)\n",
    "\n",
    "model = models.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[model.outputs, model.get_layer('tf_op_layer_Softmax').output])\n",
    "\n",
    "pred, att_weights = model(tokenized[np.newaxis, ...])\n",
    "print(\"Softmax output:\")\n",
    "print(pred[0][0, -1, :])\n",
    "print('Argmax token:', VOCABULARY[np.argmax(pred[0][0, -1, :])])\n",
    "\n",
    "print(\"Attention weights:\")\n",
    "plt.plot(att_weights[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
