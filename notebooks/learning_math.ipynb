{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, models\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '+',\n",
       " '=',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'F',\n",
       " '!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCABULARY = [str(d) for d in range(10)] + ['+', '=', 'Q', 'E', 'F', '!']\n",
    "VOCABULARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97+53Q0+7+3E10Q1+9+5E15F150!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data(n_samples, max_n_digits, seed, min_n_digits=1):\n",
    "    random.seed(seed)\n",
    "    already_generated = set()\n",
    "    \n",
    "    while True:\n",
    "        if len(already_generated) >= n_samples:\n",
    "            break\n",
    "        \n",
    "        n_digits = random.randint(min_n_digits, max_n_digits)\n",
    "        \n",
    "        a = random.randint(0, 10 ** n_digits - 1)\n",
    "        b = random.randint(0, 10 ** n_digits - 1)\n",
    "        \n",
    "        if (a, b) in already_generated:\n",
    "            continue\n",
    "        \n",
    "        already_generated.add((a, b))\n",
    "        \n",
    "        problem = f'{a:0{n_digits}d}+{b:0{n_digits}d}'\n",
    "\n",
    "        carry = 0\n",
    "        \n",
    "        for significance in range(n_digits):\n",
    "            a_digit = (a // 10 ** significance) % 10\n",
    "            b_digit = (b // 10 ** significance) % 10\n",
    "            result = a_digit + b_digit + carry\n",
    "            result_digit = result % 10\n",
    "            result_carry = result // 10\n",
    "            problem += f'Q{carry}+{a_digit}+{b_digit}E{result_carry}{result_digit}'\n",
    "            carry = result_carry\n",
    "        \n",
    "        problem += f'F{a+b}!'\n",
    "        \n",
    "        yield problem\n",
    "\n",
    "next(data(100, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    s = list(s)\n",
    "    return np.array([VOCABULARY.index(c) for c in s], dtype=np.int32)\n",
    "\n",
    "def detokenize(arr):\n",
    "    return ''.join([VOCABULARY[x] for x in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def system_1(s):\n",
    "    return f'{eval(s):02d}'\n",
    "\n",
    "system_1('7+1+0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset):\n",
    "    for example in dataset:\n",
    "        idxs = [(m.start(0), m.end(0))\n",
    "                for m in re.finditer('Q.\\+.\\+.E|F.*!', example[1:])]\n",
    "        \n",
    "        tokens = tokenize(example)\n",
    "        inputs = tokens[:-1]\n",
    "        targets = tokens[1:]\n",
    "        \n",
    "        mask = np.array([0] * len(targets))\n",
    "        for s, e in idxs:\n",
    "            mask[s:e] = 1\n",
    "        \n",
    "        yield inputs, targets, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class System1Error(Exception):\n",
    "    pass\n",
    "\n",
    "def decode_generator(model, a, b):\n",
    "    n_digits = max(len(str(a)), len(str(b)))\n",
    "    ex = f\"{a:0{n_digits}d}+{b:0{n_digits}d}\"\n",
    "    tokenized = tokenize(ex).astype(np.int32)\n",
    "    \n",
    "    while True:\n",
    "        while not tokenized[-1] in (VOCABULARY.index('E'), VOCABULARY.index('!')):\n",
    "            pred = model(tokenized[np.newaxis, ...], training=False)\n",
    "            pred = pred.numpy()\n",
    "            next_token = np.argmax(pred, axis=-1)[0, -1].astype(np.int32)\n",
    "            tokenized = np.append(tokenized, next_token)\n",
    "            yield detokenize(tokenized)\n",
    "\n",
    "        if tokenized[-1] == VOCABULARY.index('E'):\n",
    "            # Call system 1\n",
    "            query = detokenize(tokenized)[-6:-1]\n",
    "            try:\n",
    "                ans = system_1(query)\n",
    "            except Exception as e:\n",
    "                raise System1Error(e)\n",
    "            tokenized_ans = tokenize(ans)\n",
    "            tokenized = np.append(tokenized, tokenized_ans)\n",
    "            yield detokenize(tokenized)\n",
    "\n",
    "        elif tokenized[-1] == VOCABULARY.index('!'):\n",
    "            break\n",
    "\n",
    "def decode(model, a, b):\n",
    "    for detokenized in decode_generator(model, a, b):\n",
    "        pass\n",
    "    return detokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset):\n",
    "    n_correct = 0\n",
    "    for example in test_dataset:\n",
    "        i = example.index('Q')\n",
    "        ab = example[:i]\n",
    "        i = ab.index('+')\n",
    "        a = int(ab[:i])\n",
    "        b = int(ab[i:])\n",
    "\n",
    "        try:\n",
    "            ans = decode(model, a, b)\n",
    "            i = ans.index('F')\n",
    "            ans = ans[i+1:-1]\n",
    "            ans = int(ans)\n",
    "\n",
    "            if ans == a + b:\n",
    "                n_correct += 1\n",
    "        except ValueError as err:\n",
    "            print(\"ValueError in eval:\", err)\n",
    "        except System1Error as err:\n",
    "            print(\"System1Error in eval:\", err)\n",
    "\n",
    "    return n_correct / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size):\n",
    "    inputs = layers.Input((None,), dtype=tf.int32)\n",
    "    x = inputs\n",
    "    x = layers.Embedding(vocab_size, 64)(x)\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    x = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    model = models.Model(inputs, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_model(vocab_size):\n",
    "    inputs = layers.Input((None,), dtype=tf.int32)\n",
    "    x = inputs\n",
    "    x = layers.Embedding(vocab_size, 64)(x)\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    \n",
    "    # Attention mechanism.\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    keys = layers.Dense(128)(x)\n",
    "    look_ahead_mask = (1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)) * -1e9\n",
    "    look_ahead_mask = look_ahead_mask[tf.newaxis, ...]\n",
    "    attention_scores = x @ tf.transpose(keys, [0, 2, 1])\n",
    "    attention_scores = attention_scores + look_ahead_mask\n",
    "    attention_weights = tf.nn.softmax(attention_scores, name=\"attention_weights\")\n",
    "    x_att = attention_weights @ x\n",
    "    x = layers.Concatenate()([x, x_att])\n",
    "    \n",
    "    x = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    model = models.Model(inputs, x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_copy_model(vocab_size):\n",
    "    inputs = layers.Input((None,), dtype=tf.int32)\n",
    "    x = inputs\n",
    "    x = layers.Embedding(vocab_size, 64)(x)\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    \n",
    "    batch_size = tf.shape(x)[0]\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    keys = layers.Dense(128)(x)\n",
    "    look_ahead_mask = (1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)) * -1e9\n",
    "    look_ahead_mask = look_ahead_mask[tf.newaxis, ...]\n",
    "    attention_scores = x @ tf.transpose(keys, [0, 2, 1])\n",
    "    attention_scores = attention_scores + look_ahead_mask\n",
    "    attention_weights = tf.nn.softmax(attention_scores, name=\"attention_weights\")\n",
    "    x_att = attention_weights @ x\n",
    "    x_att = layers.Dropout(0.2)(x_att)\n",
    "    \n",
    "    # Generative distribution.\n",
    "    gen_dist = layers.Dense(vocab_size, activation='softmax')(x_att)\n",
    "    \n",
    "    # Copy mechanism based distribution.\n",
    "    indices = tf.range(batch_size, dtype=tf.int32)[:, tf.newaxis]  # (bs, 1)\n",
    "    indices = tf.tile(indices, [1, seq_len])  # (bs, seq_len)\n",
    "    indices = tf.stack((indices, inputs), axis=2)\n",
    "    #indices = tf.transpose(indices, perm=[1, 2, 0])  # (bs, seq_len, 2)\n",
    "    updates = tf.transpose(attention_weights, perm=[0, 2, 1])\n",
    "    output_shape = [batch_size, vocab_size, seq_len]\n",
    "    copy_dist = tf.scatter_nd(indices, updates, output_shape)\n",
    "    copy_dist = tf.transpose(copy_dist, [0, 2, 1])\n",
    "    \n",
    "    # Combine distributions.\n",
    "    p_gen_pre_logit = layers.Concatenate()([x_att, keys])\n",
    "    p_gen = layers.Dense(1, activation=\"sigmoid\")(p_gen_pre_logit)\n",
    "    dist = p_gen * gen_dist + (1 - p_gen) * copy_dist \n",
    "    \n",
    "    model = models.Model(inputs, dist)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_type):\n",
    "    vocab_size = len(VOCABULARY)\n",
    "    if model_type == \"baseline\":\n",
    "        model = build_model(vocab_size)\n",
    "    elif model_type == \"attention\":\n",
    "        model = build_attention_model(vocab_size)\n",
    "    elif model_type == \"copy\":\n",
    "        model = build_copy_model(vocab_size)\n",
    "    else:\n",
    "        raise Exception(\"Invalid model.\")\n",
    "    model.build(input_shape=(None, None))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_experiment(train_dataset, test_dataset, model):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    batch_size = 64\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(\n",
    "        lambda: data_generator(train_dataset),\n",
    "        output_types=(tf.int32, tf.int32, tf.int32),\n",
    "        output_shapes=(\n",
    "            tf.TensorShape((None,)), \n",
    "            tf.TensorShape((None,)), \n",
    "            tf.TensorShape((None,))\n",
    "        ))\n",
    "    train_ds = train_ds.shuffle(10000)\n",
    "    train_ds = train_ds.padded_batch(batch_size, padded_shapes=([None], [None], [None]))\n",
    "    train_ds = train_ds.prefetch(100)\n",
    "\n",
    "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    optimizer = optimizers.Adam(1e-3)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(inputs, targets, mask):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(inputs, training=True)\n",
    "            loss = tf.losses.sparse_categorical_crossentropy(targets, outputs)\n",
    "            loss = tf.boolean_mask(loss, tf.cast(mask, tf.bool))\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            masked_outputs = tf.boolean_mask(outputs, tf.cast(mask, tf.bool))\n",
    "            accuracy(targets, outputs, sample_weight=mask)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    accuracy_history = []\n",
    "    stop_criteria_last_n = 5\n",
    "    \n",
    "    for i, (inputs, targets, mask) in train_ds.repeat(None).take(4000).enumerate():\n",
    "        accuracy.reset_states()\n",
    "        loss = train_step(inputs, targets, mask)\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(\n",
    "                'Step', i.numpy(),\n",
    "                'Loss', loss.numpy(),\n",
    "                'Acc', accuracy.result().numpy())\n",
    "            accuracy_history.append(accuracy.result().numpy())\n",
    "            if len(accuracy_history) > stop_criteria_last_n:\n",
    "                accuracy_history = accuracy_history[1:]\n",
    "            if sum(accuracy_history) >= 1.0 * stop_criteria_last_n - 0.000001:\n",
    "                break\n",
    "    \n",
    "    accuracy = evaluate(model, test_dataset)\n",
    "    \n",
    "    return accuracy, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 1.1862833 Acc 0.65282214\n",
      "Step 200 Loss 0.68037593 Acc 0.77059436\n",
      "Step 300 Loss 0.4845533 Acc 0.8442623\n",
      "Step 400 Loss 0.29587007 Acc 0.92164946\n",
      "Step 500 Loss 0.15812694 Acc 0.97021276\n",
      "Step 600 Loss 0.07327411 Acc 0.99464667\n",
      "Step 700 Loss 0.037553713 Acc 0.99897116\n",
      "Step 800 Loss 0.022651564 Acc 1.0\n",
      "Step 900 Loss 0.01487125 Acc 1.0\n",
      "Step 1000 Loss 0.009957217 Acc 1.0\n",
      "Step 1100 Loss 0.0073087015 Acc 1.0\n",
      "Step 1200 Loss 0.0058434503 Acc 1.0\n",
      "ValueError in eval: substring not found\n",
      "System1Error in eval: unexpected EOF while parsing (<string>, line 1)\n",
      "System1Error in eval: name 'Q0' is not defined\n",
      "ValueError in eval: invalid literal for int() with base 10: '15F'\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F3'\n",
      "System1Error in eval: unexpected EOF while parsing (<string>, line 1)\n",
      "ValueError in eval: substring not found\n",
      "System1Error in eval: unexpected EOF while parsing (<string>, line 1)\n",
      "System1Error in eval: invalid syntax (<string>, line 1)\n",
      "ValueError in eval: invalid literal for int() with base 10: '1F1'\n",
      "ValueError in eval: invalid literal for int() with base 10: '888888888888+8+0Q0+0+0E00Q0+0+0E0080'\n",
      "Step 100 Loss 1.5299813 Acc 0.61904764\n",
      "Step 200 Loss 0.84820324 Acc 0.6941392\n",
      "Step 300 Loss 0.7499559 Acc 0.7338783\n",
      "Step 400 Loss 0.68583757 Acc 0.7611807\n",
      "Step 500 Loss 0.6252331 Acc 0.7861011\n",
      "Step 600 Loss 0.56926256 Acc 0.8061224\n",
      "Step 700 Loss 0.47682616 Acc 0.8441203\n",
      "Step 800 Loss 0.38035524 Acc 0.8906999\n",
      "Step 900 Loss 0.31543842 Acc 0.91351354\n",
      "Step 1000 Loss 0.22168742 Acc 0.9455217\n",
      "Step 1100 Loss 0.159135 Acc 0.9668508\n",
      "Step 1200 Loss 0.109449804 Acc 0.98630136\n",
      "Step 1300 Loss 0.078042716 Acc 0.9910554\n",
      "Step 1400 Loss 0.05438614 Acc 0.9981966\n",
      "Step 1500 Loss 0.037445452 Acc 0.9980952\n",
      "Step 1600 Loss 0.032589838 Acc 0.99822694\n",
      "Step 1700 Loss 0.021109069 Acc 1.0\n",
      "Step 1800 Loss 0.016696393 Acc 1.0\n",
      "Step 1900 Loss 0.012067419 Acc 1.0\n",
      "Step 2000 Loss 0.010343065 Acc 1.0\n",
      "Step 2100 Loss 0.008208174 Acc 1.0\n",
      "Step 100 Loss 1.5621746 Acc 0.58465606\n",
      "Step 200 Loss 0.87198675 Acc 0.692029\n",
      "Step 300 Loss 0.76194113 Acc 0.7173524\n",
      "Step 400 Loss 0.7113558 Acc 0.7504409\n",
      "Step 500 Loss 0.6436431 Acc 0.77081466\n",
      "Step 600 Loss 0.58616704 Acc 0.788975\n",
      "Step 700 Loss 0.50414705 Acc 0.8205591\n",
      "Step 800 Loss 0.41765955 Acc 0.8666667\n",
      "Step 900 Loss 0.35005274 Acc 0.89285713\n",
      "Step 1000 Loss 0.26177704 Acc 0.92233855\n",
      "Step 1100 Loss 0.19039772 Acc 0.95837027\n",
      "Step 1200 Loss 0.13421999 Acc 0.97325283\n",
      "Step 1300 Loss 0.100248985 Acc 0.98471224\n",
      "Step 1400 Loss 0.058536775 Acc 0.9982699\n",
      "Step 1500 Loss 0.046379697 Acc 0.9956522\n",
      "Step 1600 Loss 0.029428855 Acc 0.99911815\n",
      "Step 1700 Loss 0.026532382 Acc 1.0\n",
      "Step 1800 Loss 0.02227902 Acc 1.0\n",
      "Step 1900 Loss 0.017268917 Acc 1.0\n",
      "Step 2000 Loss 0.014422558 Acc 1.0\n",
      "Step 100 Loss 1.4663426 Acc 0.5731394\n",
      "Step 200 Loss 0.89904237 Acc 0.6930519\n",
      "Step 300 Loss 0.7599447 Acc 0.7248495\n",
      "Step 400 Loss 0.6971414 Acc 0.74805194\n",
      "Step 500 Loss 0.6313308 Acc 0.7730802\n",
      "Step 600 Loss 0.5839829 Acc 0.79777205\n",
      "Step 700 Loss 0.523813 Acc 0.8143972\n",
      "Step 800 Loss 0.45513096 Acc 0.84136724\n",
      "Step 900 Loss 0.3869459 Acc 0.8855679\n",
      "Step 1000 Loss 0.26418537 Acc 0.9235395\n",
      "Step 1100 Loss 0.22217138 Acc 0.9506066\n",
      "Step 1200 Loss 0.16051228 Acc 0.9653979\n",
      "Step 1300 Loss 0.11818745 Acc 0.9778369\n",
      "Step 1400 Loss 0.084868625 Acc 0.9906383\n",
      "Step 1500 Loss 0.056889568 Acc 0.9991342\n",
      "Step 1600 Loss 0.04283627 Acc 0.9956408\n",
      "Step 1700 Loss 0.032677457 Acc 0.9991319\n",
      "Step 1800 Loss 0.02744842 Acc 1.0\n",
      "Step 1900 Loss 0.02235809 Acc 1.0\n",
      "Step 2000 Loss 0.021123797 Acc 1.0\n",
      "Step 2100 Loss 0.012152342 Acc 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data(\n",
    "    n_samples=5000,\n",
    "    max_n_digits=2,\n",
    "    seed=0)\n",
    "dataset = list(dataset)\n",
    "\n",
    "test_dataset = dataset[-300:]\n",
    "\n",
    "n_train_sizes = [100, 500, 1000, 2000]\n",
    "accuracies = []\n",
    "\n",
    "for n_train in n_train_sizes:\n",
    "    train_dataset = dataset[:n_train]\n",
    "    model = get_model(model_type=\"baseline\")\n",
    "    accuracy, _ = run_experiment(train_dataset, test_dataset, model)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(n_train_sizes, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02666666666666667, 0.71, 0.9433333333333334, 0.9933333333333333]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline + self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 1.4945395 Acc 0.6157068\n",
      "Step 200 Loss 0.71257013 Acc 0.74570817\n",
      "Step 300 Loss 0.6223441 Acc 0.7964323\n",
      "Step 400 Loss 0.5438031 Acc 0.8249497\n",
      "Step 500 Loss 0.38787943 Acc 0.88272923\n",
      "Step 600 Loss 0.27193817 Acc 0.92142856\n",
      "Step 700 Loss 0.17974058 Acc 0.9497908\n",
      "Step 800 Loss 0.20003377 Acc 0.94824016\n",
      "Step 900 Loss 0.12747312 Acc 0.97308487\n",
      "Step 1000 Loss 0.0876744 Acc 0.9871106\n",
      "Step 1100 Loss 0.05597739 Acc 0.9958678\n",
      "Step 1200 Loss 0.036519613 Acc 0.997921\n",
      "Step 1300 Loss 0.024524229 Acc 0.9989339\n",
      "Step 1400 Loss 0.018582297 Acc 1.0\n",
      "Step 1500 Loss 0.012929136 Acc 1.0\n",
      "Step 1600 Loss 0.009713276 Acc 1.0\n",
      "Step 1700 Loss 0.008025642 Acc 1.0\n",
      "Step 1800 Loss 0.0064589335 Acc 1.0\n",
      "ValueError in eval: invalid literal for int() with base 10: '1F88'\n",
      "System1Error in eval: invalid syntax (<string>, line 1)\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F99'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F188'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F15'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F81'\n",
      "System1Error in eval: name 'Q0' is not defined\n",
      "ValueError in eval: invalid literal for int() with base 10: '1F96'\n",
      "ValueError in eval: invalid literal for int() with base 10: '1F47'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F18'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F88'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F113'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F11'\n",
      "System1Error in eval: invalid syntax (<string>, line 1)\n",
      "ValueError in eval: invalid literal for int() with base 10: '1F96'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F129'\n",
      "ValueError in eval: invalid literal for int() with base 10: 'F138'\n",
      "System1Error in eval: invalid syntax (<string>, line 1)\n",
      "System1Error in eval: invalid syntax (<string>, line 1)\n",
      "System1Error in eval: invalid syntax (<string>, line 1)\n",
      "Step 100 Loss 1.8419912 Acc 0.46402213\n",
      "Step 200 Loss 1.0512199 Acc 0.65627867\n",
      "Step 300 Loss 0.7912355 Acc 0.7206021\n",
      "Step 400 Loss 0.7265875 Acc 0.7388128\n",
      "Step 500 Loss 0.70978475 Acc 0.75915754\n",
      "Step 600 Loss 0.64995533 Acc 0.78373206\n",
      "Step 700 Loss 0.5894177 Acc 0.8153153\n",
      "Step 800 Loss 0.47029495 Acc 0.85805863\n",
      "Step 900 Loss 0.3599512 Acc 0.9002822\n",
      "Step 1000 Loss 0.32068062 Acc 0.9094236\n",
      "Step 1100 Loss 0.19777942 Acc 0.9458972\n",
      "Step 1200 Loss 0.1360396 Acc 0.96875\n",
      "Step 1300 Loss 0.09994104 Acc 0.9770642\n",
      "Step 1400 Loss 0.058562454 Acc 0.99253035\n",
      "Step 1500 Loss 0.03244482 Acc 0.9981516\n",
      "Step 1600 Loss 0.01896251 Acc 1.0\n",
      "Step 1700 Loss 0.013737502 Acc 1.0\n",
      "Step 1800 Loss 0.01088162 Acc 1.0\n",
      "Step 1900 Loss 0.008636003 Acc 1.0\n",
      "Step 2000 Loss 0.0070806416 Acc 1.0\n",
      "Step 100 Loss 1.840142 Acc 0.5212766\n",
      "Step 200 Loss 0.888795 Acc 0.6796537\n",
      "Step 300 Loss 0.7643263 Acc 0.72869563\n",
      "Step 400 Loss 0.6851094 Acc 0.75728154\n",
      "Step 500 Loss 0.6057733 Acc 0.8016014\n",
      "Step 600 Loss 0.51964825 Acc 0.82913166\n",
      "Step 700 Loss 0.42615777 Acc 0.8770795\n",
      "Step 800 Loss 0.27953485 Acc 0.9297597\n",
      "Step 900 Loss 0.19047084 Acc 0.95\n",
      "Step 1000 Loss 0.11685133 Acc 0.9739677\n",
      "Step 1100 Loss 0.06854128 Acc 0.99030834\n",
      "Step 1200 Loss 0.044823118 Acc 0.9965458\n",
      "Step 1300 Loss 0.03035149 Acc 1.0\n",
      "Step 1400 Loss 0.0213715 Acc 1.0\n",
      "Step 1500 Loss 0.015348879 Acc 1.0\n",
      "Step 1600 Loss 0.01105716 Acc 1.0\n",
      "Step 1700 Loss 0.0088163745 Acc 1.0\n",
      "Step 100 Loss 1.7196798 Acc 0.5109553\n",
      "Step 200 Loss 1.0629988 Acc 0.6564952\n",
      "Step 300 Loss 0.8527479 Acc 0.7022184\n",
      "Step 400 Loss 0.81470037 Acc 0.71416384\n",
      "Step 500 Loss 0.76813775 Acc 0.7339688\n",
      "Step 600 Loss 0.7279041 Acc 0.7398092\n",
      "Step 700 Loss 0.65888435 Acc 0.77014416\n",
      "Step 800 Loss 0.62742096 Acc 0.78443116\n",
      "Step 900 Loss 0.5588078 Acc 0.8363636\n",
      "Step 1000 Loss 0.47607103 Acc 0.8695652\n",
      "Step 1100 Loss 0.41429025 Acc 0.891962\n",
      "Step 1200 Loss 0.35205498 Acc 0.90783805\n",
      "Step 1300 Loss 0.30028102 Acc 0.91572547\n",
      "Step 1400 Loss 0.25364414 Acc 0.9307432\n",
      "Step 1500 Loss 0.21326815 Acc 0.94641316\n",
      "Step 1600 Loss 0.18262124 Acc 0.9508197\n",
      "Step 1700 Loss 0.15522406 Acc 0.9664014\n",
      "Step 1800 Loss 0.1104411 Acc 0.9769033\n",
      "Step 1900 Loss 0.095926106 Acc 0.98253274\n",
      "Step 2000 Loss 0.06603454 Acc 0.99058217\n",
      "Step 2100 Loss 0.053874776 Acc 0.9948097\n",
      "Step 2200 Loss 0.04399038 Acc 0.99571186\n",
      "Step 2300 Loss 0.03333827 Acc 0.9982669\n",
      "Step 2400 Loss 0.023149513 Acc 0.9982729\n",
      "Step 2500 Loss 0.017109375 Acc 1.0\n",
      "Step 2600 Loss 0.016539099 Acc 1.0\n",
      "Step 2700 Loss 0.011676754 Acc 1.0\n",
      "Step 2800 Loss 0.010862077 Acc 1.0\n",
      "Step 2900 Loss 0.009539674 Acc 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data(\n",
    "    n_samples=5000,\n",
    "    max_n_digits=2,\n",
    "    seed=0)\n",
    "dataset = list(dataset)\n",
    "\n",
    "test_dataset = dataset[-300:]\n",
    "\n",
    "n_train_sizes = [100, 500, 1000, 2000]\n",
    "accuracies = []\n",
    "for n_train in n_train_sizes:\n",
    "    train_dataset = dataset[:n_train]\n",
    "    model = get_model(model_type=\"attention\")\n",
    "    accuracy, _ = run_experiment(train_dataset, test_dataset, model)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(n_train_sizes, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06666666666666667, 0.9466666666666667, 0.97, 1.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline + self attention + copy mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 0.38411444 Acc 0.9507042\n",
      "Step 200 Loss 0.021667484 Acc 1.0\n",
      "Step 300 Loss 0.0070585534 Acc 1.0\n",
      "Step 400 Loss 0.0036370384 Acc 1.0\n",
      "Step 500 Loss 0.0022463168 Acc 1.0\n",
      "Step 600 Loss 0.001534596 Acc 1.0\n",
      "Step 100 Loss 0.44649592 Acc 0.92156863\n",
      "Step 200 Loss 0.016784322 Acc 1.0\n",
      "Step 300 Loss 0.0058229836 Acc 1.0\n",
      "Step 400 Loss 0.0029924125 Acc 1.0\n",
      "Step 500 Loss 0.0018798029 Acc 1.0\n",
      "Step 600 Loss 0.0013016862 Acc 1.0\n",
      "Step 100 Loss 0.8320273 Acc 0.7452229\n",
      "Step 200 Loss 0.08308071 Acc 0.99486655\n",
      "Step 300 Loss 0.03328858 Acc 0.9979317\n",
      "Step 400 Loss 0.010380074 Acc 1.0\n",
      "Step 500 Loss 0.0072118035 Acc 0.9989637\n",
      "Step 600 Loss 0.003904746 Acc 1.0\n",
      "Step 700 Loss 0.0027104837 Acc 1.0\n",
      "Step 800 Loss 0.0019478889 Acc 1.0\n",
      "Step 900 Loss 0.0015710242 Acc 1.0\n",
      "Step 1000 Loss 0.0012098234 Acc 1.0\n",
      "Step 100 Loss 0.6340881 Acc 0.8931841\n",
      "Step 200 Loss 0.04874879 Acc 0.9989733\n",
      "Step 300 Loss 0.01375618 Acc 1.0\n",
      "Step 400 Loss 0.0057922937 Acc 1.0\n",
      "Step 500 Loss 0.0034799408 Acc 1.0\n",
      "Step 600 Loss 0.0024150668 Acc 1.0\n",
      "Step 700 Loss 0.0017707398 Acc 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data(\n",
    "    n_samples=5000,\n",
    "    max_n_digits=2,\n",
    "    seed=0)\n",
    "dataset = list(dataset)\n",
    "\n",
    "test_dataset = dataset[-300:]\n",
    "\n",
    "n_train_sizes = [20, 50, 75, 100]\n",
    "accuracies = []\n",
    "for n_train in n_train_sizes:\n",
    "    train_dataset = dataset[:n_train]\n",
    "    model = get_model(model_type=\"copy\")\n",
    "    accuracy, _ = run_experiment(train_dataset, test_dataset, model)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "plt.plot(n_train_sizes, accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9033333333333333, 0.97, 0.9933333333333333, 0.9933333333333333]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing num digits in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = data(\n",
    "    n_samples=20000,\n",
    "    max_n_digits=10,\n",
    "    seed=0)\n",
    "train_dataset = list(train_dataset)\n",
    "\n",
    "test_dataset = data(\n",
    "    n_samples=100,\n",
    "    max_n_digits=11,\n",
    "    min_n_digits=11,\n",
    "    seed=0)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "accuracy, model = run_experiment(train_dataset, test_dataset, model_type=\"copy\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "decode(model, 11111, 22222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ex = \"123+567Q0+3+7E1\"\n",
    "tokenized = tokenize(ex)\n",
    "\n",
    "model2 = models.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[model.outputs, model.get_layer('tf_op_layer_add_1').output])\n",
    "\n",
    "pred, att_weights = model2(tokenized[np.newaxis, ...])\n",
    "print(\"Softmax output:\")\n",
    "print(pred[0][0, -1, :])\n",
    "print('Argmax token:', VOCABULARY[np.argmax(pred[0][0, -1, :])])\n",
    "\n",
    "print(\"Attention weights:\")\n",
    "plt.plot(att_weights[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.89, 0.9966666666666667]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing num digits in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = data(\n",
    "    n_samples=20000,\n",
    "    max_n_digits=10,\n",
    "    seed=0)\n",
    "train_dataset = list(train_dataset)\n",
    "\n",
    "test_dataset = data(\n",
    "    n_samples=100,\n",
    "    max_n_digits=11,\n",
    "    min_n_digits=11,\n",
    "    seed=0)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "accuracy, model = run_experiment(train_dataset, test_dataset, model_type=\"copy\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(model, 11111, 22222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 1.7510577 Acc 0.3577692\n",
      "Step 200 Loss 0.7363128 Acc 0.66133237\n",
      "Step 300 Loss 0.23070818 Acc 0.93458277\n",
      "Step 400 Loss 0.16577663 Acc 0.95468163\n",
      "Step 500 Loss 0.12412925 Acc 0.9715262\n",
      "Step 600 Loss 0.08000709 Acc 0.97229505\n",
      "Step 700 Loss 0.058957323 Acc 0.98364484\n",
      "Step 800 Loss 0.048188433 Acc 0.9865219\n",
      "Step 900 Loss 0.034118593 Acc 0.99128854\n",
      "Step 1000 Loss 0.06879918 Acc 0.98642063\n",
      "Step 1100 Loss 0.04306678 Acc 0.98717946\n",
      "Step 1200 Loss 0.03255617 Acc 0.9874389\n",
      "Step 1300 Loss 0.021019923 Acc 0.9956076\n",
      "Step 1400 Loss 0.026411908 Acc 0.99159354\n",
      "Step 1500 Loss 0.027465748 Acc 0.98948896\n",
      "Step 1600 Loss 0.025083784 Acc 0.99016035\n",
      "Step 1700 Loss 0.02650359 Acc 0.98736006\n",
      "Step 1800 Loss 0.017496284 Acc 0.99508774\n",
      "Step 1900 Loss 0.032678075 Acc 0.9862069\n",
      "Step 2000 Loss 0.028039798 Acc 0.9883063\n",
      "Step 2100 Loss 0.028856978 Acc 0.98493975\n",
      "Step 2200 Loss 0.022195157 Acc 0.9897563\n",
      "Step 2300 Loss 0.034734696 Acc 0.98366606\n",
      "Step 2400 Loss 0.024519438 Acc 0.9919083\n",
      "Step 2500 Loss 0.024012906 Acc 0.9921232\n",
      "Step 2600 Loss 0.026947502 Acc 0.98575497\n",
      "Step 2700 Loss 0.022979721 Acc 0.9906297\n",
      "Step 2800 Loss 0.02128212 Acc 0.9899381\n",
      "Step 2900 Loss 0.016677452 Acc 0.9925623\n",
      "Step 3000 Loss 0.013230887 Acc 0.9953372\n",
      "Step 3100 Loss 0.007158113 Acc 0.9986877\n",
      "Step 3200 Loss 0.010597197 Acc 0.9960907\n",
      "Step 3300 Loss 0.0076962914 Acc 0.99887216\n",
      "Step 3400 Loss 0.0046956567 Acc 1.0\n",
      "Step 3500 Loss 0.005498334 Acc 1.0\n",
      "Step 3600 Loss 0.0041176192 Acc 1.0\n",
      "Step 3700 Loss 0.0027175476 Acc 1.0\n",
      "Step 3800 Loss 0.00217566 Acc 0.9996249\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "ValueError in eval: substring not found\n",
      "Accuracy with max 8 digits, evaluating on 9 digits: 0.01\n"
     ]
    }
   ],
   "source": [
    "model = get_model(model_type=\"copy\")\n",
    "for max_n_digits in [8]: #[2,3,4,6,8]:\n",
    "    train_dataset = data(\n",
    "        n_samples=10000,\n",
    "        max_n_digits=max_n_digits,\n",
    "        seed=0)\n",
    "    train_dataset = list(train_dataset)\n",
    "\n",
    "    test_dataset = data(\n",
    "        n_samples=100,\n",
    "        max_n_digits=max_n_digits+1,\n",
    "        min_n_digits=max_n_digits+1,\n",
    "        seed=0)\n",
    "    test_dataset = list(test_dataset)\n",
    "\n",
    "    accuracy, _ = run_experiment(train_dataset, test_dataset, model)\n",
    "    print(\"Accuracy with max {} digits, evaluating on {} digits: {}\".format(max_n_digits, max_n_digits + 1, \n",
    "                                                                            accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "097942384+086378036Q0+4+6E10Q1+8+3E12Q1+3+0E04Q0+2+8E10Q1+4+7E12Q1+9+3E13Q1+7+6E14Q1+9+8E18Q1+0+0E01F184320420!\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for example in test_dataset:\n",
    "    i = example.index('Q')\n",
    "    ab = example[:i]\n",
    "    i = ab.index('+')\n",
    "    a = int(ab[:i])\n",
    "    b = int(ab[i:])\n",
    "\n",
    "    try:\n",
    "        ans = decode(model, a, b)\n",
    "        i = ans.index('F')\n",
    "        ans = ans[i+1:-1]\n",
    "        ans = int(ans)\n",
    "        if ans == a + b:\n",
    "            n_correct += 1\n",
    "            print(example)\n",
    "    except ValueError as err:\n",
    "        print(\"ValueError in eval:\", err)\n",
    "    except System1Error as err:\n",
    "        print(\"System1Error in eval:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456+123456Q0+6+6E12Q1+5+5E11Q1+4+4E09Q0+3+3E06Q0+2+2E04Q0+1+1E02F246912!\n"
     ]
    }
   ],
   "source": [
    "print(decode(model, 123456, 123456))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(chars, alpha):\n",
    "    return \"\".join([f\"<span style='color: rgba(0, 0, 0, {p * 2/3 + 1/3})'>{char}</span>\" \n",
    "                    for char, p in zip(chars, alpha)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123456789+123456789Q0+8+9E17Q1+7+7E15Q1+6+6E13Q1+6+6E13!'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(model, 123456789, 123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=[model.outputs, \n",
    "             model.get_layer('tf_op_layer_add_1').output, \n",
    "             model.get_layer('tf_op_layer_attention_weights').output,\n",
    "             model.get_layer('dense_2').output,\n",
    "             model.get_layer('tf_op_layer_transpose_2').output,\n",
    "             model.get_layer('dense_1').output\n",
    "            ])\n",
    "\n",
    "decode_stepper = decode_generator(model, 11111111, 22222222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:\n",
      "11111111+22222222Q0+1+2E03Q0+1+2E\n",
      "\n",
      "Predicted next token: E\n",
      "p_gen for next token: 1.0\n",
      "Attention for next token:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>+</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>2</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>2</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>2</span><span style='color: rgba(0, 0, 0, 0.3333333333333343)'>2</span><span style='color: rgba(0, 0, 0, 0.3333423261434897)'>2</span><span style='color: rgba(0, 0, 0, 0.8630666732788086)'>2</span><span style='color: rgba(0, 0, 0, 0.4702485203742981)'>2</span><span style='color: rgba(0, 0, 0, 0.33334255697870196)'>2</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>Q</span><span style='color: rgba(0, 0, 0, 0.3333333333333337)'>0</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>+</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>+</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>2</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>E</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>0</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>3</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>Q</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>0</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>+</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>1</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>+</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>2</span><span style='color: rgba(0, 0, 0, 0.3333333333333333)'>E</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical p_gen\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1<span style='color: rgba(0, 0, 0, 0.9999998410542805)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>+</span><span style='color: rgba(0, 0, 0, 0.9906498988469441)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>Q</span><span style='color: rgba(0, 0, 0, 0.9988430738449097)'>0</span><span style='color: rgba(0, 0, 0, 1.0)'>+</span><span style='color: rgba(0, 0, 0, 0.3334324172659156)'>1</span><span style='color: rgba(0, 0, 0, 1.0)'>+</span><span style='color: rgba(0, 0, 0, 0.3333861199110591)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>E</span><span style='color: rgba(0, 0, 0, 0.9999999205271404)'>0</span><span style='color: rgba(0, 0, 0, 1.0)'>3</span><span style='color: rgba(0, 0, 0, 0.99999205271403)'>Q</span><span style='color: rgba(0, 0, 0, 0.33333333343126825)'>0</span><span style='color: rgba(0, 0, 0, 0.9999970595041912)'>+</span><span style='color: rgba(0, 0, 0, 0.3333333334152246)'>1</span><span style='color: rgba(0, 0, 0, 0.9999994436899822)'>+</span><span style='color: rgba(0, 0, 0, 0.33333336290831284)'>2</span><span style='color: rgba(0, 0, 0, 1.0)'>E</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted copy and gen distributions (over vocabulary)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex = next(decode_stepper)\n",
    "print(\"Problem:\")\n",
    "print(ex)\n",
    "\n",
    "# Tokenize and predict next token\n",
    "tokenized = tokenize(ex)\n",
    "pred, output_prob, att_weights, p_gen, copy_dist, gen_dist = model2(tokenized[np.newaxis, ...], training=False)\n",
    "\n",
    "# Print info about model prediction\n",
    "print()\n",
    "print(f\"Predicted next token: {VOCABULARY[np.argmax(pred[0][0, -1, :])]}\")\n",
    "\n",
    "last_p_gen = p_gen[0, -1, :][0]\n",
    "print(f\"p_gen for next token: {last_p_gen}\")\n",
    "print(\"Attention for next token:\")\n",
    "display(Markdown(colorize(ex, att_weights[0, -1, :].numpy())))\n",
    "\n",
    "print(\"Historical p_gen\")\n",
    "display(Markdown(ex[0] + colorize(ex[1:], p_gen[0, :-1, 0].numpy())))\n",
    "\n",
    "print(\"Weighted copy and gen distributions (over vocabulary)\")\n",
    "plt.figure()\n",
    "plt.plot(copy_dist[0, -1, :] * (1 - last_p_gen))\n",
    "plt.plot(gen_dist[0, -1, :] * last_p_gen)\n",
    "plt.xticks(range(16), VOCABULARY)\n",
    "_ = plt.legend([\"copy dist\", \"gen dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = decode_generator(model, 123, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123+123Q0+3+3E06Q0+2+2E'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
